<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>GPT‑5 Black UI (Ollama Edition)</title>
<style>
    body {
        margin: 0;
        background: #000;
        color: #fff;
        font-family: Arial, sans-serif;
        display: flex;
        flex-direction: column;
        height: 100vh;
    }

    #chat {
        flex: 1;
        padding: 20px;
        overflow-y: auto;
        font-size: 18px;
        line-height: 1.5;
    }

    .msg {
        margin-bottom: 20px;
        padding: 12px 16px;
        border-radius: 8px;
        max-width: 80%;
    }

    .user {
        background: #111;
        border-left: 4px solid #0af;
        align-self: flex-end;
    }

    .ai {
        background: #111;
        border-left: 4px solid #0f0;
        align-self: flex-start;
    }

    #inputBar {
        display: flex;
        padding: 10px;
        background: #111;
    }

    #prompt {
        flex: 1;
        padding: 12px;
        font-size: 18px;
        border: none;
        outline: none;
        background: #000;
        color: #fff;
        border: 1px solid #333;
        border-radius: 6px;
    }

    #sendBtn {
        margin-left: 10px;
        padding: 12px 20px;
        background: #0af;
        border: none;
        color: #000;
        font-weight: bold;
        border-radius: 6px;
        cursor: pointer;
    }
</style>
</head>
<body>

<div id="chat"></div>

<div id="inputBar">
    <input id="prompt" type="text" placeholder="Ask something…" />
    <button id="sendBtn">Send</button>
</div>

<script>
// ------------------------------
//  FIXED: Ollama request
// ------------------------------
async function fakeModelReply(prompt) {
    try {
        const response = await fetch("http://localhost:11434/api/chat", {
            method: "POST",
            headers: {
                "Content-Type": "application/json"
            },
            body: JSON.stringify({
                model: "gemma:2b",   // YOU SAID YOU INSTALLED THIS ONE
                messages: [
                    { role: "user", content: prompt }
                ]
            })
        });

        const data = await response.json();
        return data.message?.content || "No response from local model.";
    } catch (err) {
        return "Error talking to Ollama.";
    }
}

// ------------------------------
//  UI helpers
// ------------------------------
function addMessage(text, cls) {
    const chat = document.getElementById("chat");
    const div = document.createElement("div");
    div.className = "msg " + cls;
    div.textContent = text;
    chat.appendChild(div);
    chat.scrollTop = chat.scrollHeight;
}

// ------------------------------
//  FIXED: Send message function
// ------------------------------
async function sendMessage() {
    const input = document.getElementById("prompt");
    const text = input.value.trim();
    if (!text) return;

    addMessage(text, "user");
    input.value = "";

    const reply = await fakeModelReply(text);
    addMessage(reply, "ai");
}

// ------------------------------
//  FIXED: Event listeners ALWAYS attach
// ------------------------------
document.addEventListener("DOMContentLoaded", () => {
    document.getElementById("sendBtn").addEventListener("click", sendMessage);
    document.getElementById("prompt").addEventListener("keydown", e => {
        if (e.key === "Enter") sendMessage();
    });
});
</script>

</body>
</html>
